{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-06-17 12:18:30,450] Making new env: CartPole-v0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Transition = namedtuple(\"Transition\", ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "    \n",
    "    def push(self, *args):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3= nn.BatchNorm2d(32)\n",
    "        self.head = nn.Linear(448, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADWCAYAAADBwHkCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFH1JREFUeJzt3X2QXXV9x/H3J7ubkIQYkgBpIJEVDFhwJCgFRGoRhEZa\nBaczCB0hMFSxRYWRqoAzFVtnqlMe7IwdqgiIolhEEUx9SgKW0iqSYIjhMYihJG4SEnkIDwYSvv3j\n/FbOvbt37929T2fPfl4zZ/b+zjn3nM89u/u95/7OvfeniMDMzMa/Sd0OYGZmreGCbmZWEi7oZmYl\n4YJuZlYSLuhmZiXhgm5mVhIu6NZxks6SdFe3cxSJpH5JIam321ls/HJBLxlJ6yW9KOm53PTFbufq\nNknHStrQxu1fKumGdm3frBE+Gyind0fE8m6HGG8k9UbEzm7naIcyPzZ7lc/QJxBJV0n6Tq79eUkr\nlJklaamkJyU9lW7Pz637U0mflfS/6az/+5LmSPqGpGcl3SOpP7d+SPqopMckbZX0L5KG/XuT9AZJ\nyyT9TtLDkk4d4THMlHSNpAFJG1OmnjqPbzrwQ2Cf3KuWfdJZ9c2SbpD0LHCWpCMk/UzS02kfX5Q0\nObfNQ3JZN0u6RNJi4BLgfWnb9zWQtUfSZenYPAb8RZ3f3SfTNranY3R8bjuXSPp1WrZK0oLc7+A8\nSeuAdfWOtaQpKdP/pcf275KmpmXHStog6UJJW9JjOnukzNYFEeGpRBOwHnhnjWXTgEeAs4A/BbYC\n89OyOcBfpXVmAN8Gvpe770+BR4EDgJnAA2lb7yR7pfc14Lrc+gHcAcwGXpvW/Zu07CzgrnR7OvAE\ncHbazmEp18E1HsMtwJfS/fYGfgGc28DjOxbYULWtS4GXgVPITm6mAm8BjkpZ+oEHgQvS+jOAAeBC\nYLfUPjK3rRtGkfVDwEPAgnSM7kjHrHeYx3xQOkb7pHY/cEC6/XHgV2kdAYcCc3K/g2Vp+1PrHWvg\nSuC2tP4M4PvAP+eO307gH4E+4CTgBWBWt//mPeX+VrodwFOLf6FZQX8OeDo3fSC3/Ejgd8DjwOkj\nbGcR8FSu/VPgU7n25cAPc+13A6tz7QAW59p/B6xIt8/i1YL+PuC/q/b9JeDTw2SaC+wApubmnQ7c\nUe/xUbug31nneF4A3JLb1y9rrHcpuYJeLytwO/Ch3LITqV3QXw9sIXvy7Kta9jBwco1MARyXa9c8\n1mRPBs+TnijSsrcCv8kdvxfz+VKmo7r9N+/p1cl96OV0StToQ4+Iu9NL/L2BmwbnS5pGdoa2GJiV\nZs+Q1BMRu1J7c25TLw7T3r1qd0/kbj8O7DNMpP2AIyU9nZvXC3y9xrp9wICkwXmT8vup9fhGkM+I\npAOBK4DDyc74e4FVafEC4NcNbLORrPsw9PgMKyIelXQB2ZPGIZJ+DHwsIn7bQKb8PkY61nuRPd5V\nubwCenLrbovKfvgXGPo7ty5yH/oEI+k8YArwW+ATuUUXkr1sPzIiXgO8ffAuTexuQe72a9M+qz0B\n/FdE7JGbdo+Iv62x7g5gz9y6r4mIQwZXGOHx1fpa0er5V5F1hSxMx+ESXj0GTwD7N7idelkHGHp8\naoqIb0bEMWRFOYDP5/ZzwEh3rcpU61hvJXtSPiS3bGZEuGCPIy7oE0g6+/ws8H7gDOATkhalxTPI\n/qGfljSb7GV4sz6eLrYuAM4H/mOYdZYCB0o6Q1Jfmv5E0h9XrxgRA8BPgMslvUbSJEkHSPqzBh7f\nZmCOpJl1Ms8AngWek/QGIP/EshSYJ+mCdAFxhqQjc9vvH7zwWy8r2auHj0qaL2kWcFGtQJIOknSc\npCnA78l+T6+kxV8B/knSQmXeJGlOjU3VPNYR8QpwNXClpL3TfveV9Od1jpcViAt6OX1fle9Dv0XZ\nB1ZuAD4fEfdFxDqys8+vp0LxBbILZ1uBnwM/akGOW8m6K1YD/wlcU71CRGwn6z8+jeysehPZ2eeU\nGts8E5hMdlH2KeBmsiI74uOLiIeAG4HH0jtYhuv+Afh74K+B7WQF7g9PQinrCWTXCzaRvXPkHWnx\nt9PPbZLuHSlrWnY18GPgPuBe4Ls18pCOxefIfjebyLqTLk7LriB7cvgJ2RPRNWS/xyEaONafJLvw\n/fP0rp/lZK/abJxQhAe4sNaTFGTdFo92O4vZROEzdDOzknBBNzMrCXe5mJmVRFNn6JIWp48PPyqp\n5lV6MzNrvzGfoafvpHiE7Kr/BuAesk/mPVDrPnvuuWf09/ePaX9mZhPVqlWrtkbEXvXWa+aTokcA\nj0bEYwCSvgWcTPYWrWH19/ezcuXKJnZpZjbxSKr5SeK8Zrpc9qXyY8Ub0rzqIB+UtFLSyieffLKJ\n3ZmZ2Uja/i6XiPhyRBweEYfvtVfdVwxmZjZGzRT0jVR+F8X8NM/MzLqgmYJ+D7BQ0uuUDQBwGtl3\nKZuZWReM+aJoROyU9GGy76PoAa6NiPtblszMzEalqe9Dj4gfAD9oURYzM2uCB7iwCSleqRwvebjP\nY0zq6etUHLOW8He5mJmVhAu6mVlJuKCbmZWEC7qZWUn4oqhNSM9vfqyi/fidNwxZp3faayraC44+\ntaI9bc6I4zqbdZzP0M3MSsIF3cysJFzQzcxKwn3oNiEFlR8kemHbE0PXefKViva8N5/U1kxmzfIZ\nuplZSbigm5mVRFNdLpLWA9uBXcDOiDi8FaHMzGz0WtGH/o6I2NqC7Zh1zK4dL1TOkIas0zNlamV7\n8tQh65gVibtczMxKotmCHsBySaskfXC4FTxItJlZZzRb0I+JiEXAu4DzJL29egUPEm1m1hnNjli0\nMf3cIukW4AjgzlYEM2unF7duqGjHrp1D1umdPquiPWXG3m3NZNasMZ+hS5ouacbgbeBEYG2rgpmZ\n2eg0c4Y+F7hF2bsDeoFvRsSPWpLKzMxGbcwFPSIeAw5tYRYzM2uCv8vFJqZh3nde39CBpM2KxO9D\nNzMrCRd0M7OScEE3MysJF3Qzs5JwQTczKwkXdDOzknBBNzMrCRd0M7OScEE3MysJF3Qzs5JwQTcz\nK4m6BV3StZK2SFqbmzdb0jJJ69LPWSNtw8zM2q+RM/SvAour5l0ErIiIhcCK1DYzsy6qW9Aj4k7g\nd1WzTwauT7evB05pcS4zMxulsfahz42IgXR7E9lgF8PyINFmZp3R9EXRiAhG+KJoDxJtZtYZYy3o\nmyXNA0g/t7QukpmZjcVYC/ptwJJ0ewlwa2vimJnZWDXytsUbgZ8BB0naIOkc4HPACZLWAe9MbTMz\n66K6Y4pGxOk1Fh3f4ixmZtYEf1LUzKwkXNDNzErCBd3MrCRc0M3MSsIF3cysJFzQzcxKwgXdzKwk\nXNDNzErCBd3MrCTqflLUrJSkbicwazmfoZuZlYQLuplZSYx1kOhLJW2UtDpNJ7U3ppmZ1dNIH/pX\ngS8CX6uaf2VEXNbyRGYdsGvH83XXkSZVz2hTGrPWGOsg0WZmVjDN9KF/RNKa1CUzq9ZKHiTazKwz\nxlrQrwL2BxYBA8DltVb0INFmZp0xpvehR8TmwduSrgaWtiyRWQe8sHVD3XWm7PFHFe3eydPaFces\nJcZ0hi5pXq75XmBtrXXNzKwz6p6hp0GijwX2lLQB+DRwrKRFQADrgXPbmNHMzBow1kGir2lDFjMz\na4K/y8UmpgbeU+73odt444/+m5mVhAu6mVlJuKCbmZWEC7qZWUm4oJuZlYQLuplZSbigm5mVhAu6\nmVlJuKCbmZWEC7qZWUm4oJuZlUQjg0QvkHSHpAck3S/p/DR/tqRlktalnzVHLTIzs/Zr5Ax9J3Bh\nRBwMHAWcJ+lg4CJgRUQsBFaktpmZdUkjg0QPRMS96fZ24EFgX+Bk4Pq02vXAKe0KaWZm9Y2qD11S\nP3AYcDcwNyIG0qJNwNwa9/Eg0WZmHdBwQZe0O/Ad4IKIeDa/LCKCbPSiITxItJlZZzRU0CX1kRXz\nb0TEd9PszYNji6afW9oT0czMGtHIu1xENuTcgxFxRW7RbcCSdHsJcGvr45mZWaMaGYLubcAZwK8k\nrU7zLgE+B9wk6RzgceDU9kQ0M7NGNDJI9F1ArcEUj29tHDMzGyt/UtTMrCRc0M3MSsIF3cysJFzQ\nzcxKwgXdzKwkXNDNzErCBd3MrCRc0M3MSsIF3cysJFzQzcxKwgXdzKwkXNDNzEqimUGiL5W0UdLq\nNJ3U/rhmZlZLI1+fOzhI9L2SZgCrJC1Ly66MiMvaF8+sRSKqmq/UvYsm9bQrjVlbNPL1uQPAQLq9\nXdLgINFmZlYgzQwSDfARSWskXStpVo37eJBoM7MOaGaQ6KuA/YFFZGfwlw93Pw8SbWbWGY30oQ87\nSHREbM4tvxpY2paEZi2w86UXKto7nt5U9z7T99qvXXHM2mLMg0RLmpdb7b3A2tbHMzOzRjUzSPTp\nkhYBAawHzm1LQjMza0gzg0T/oPVxzMxsrBrqQzcb9/w+dJsA/NF/M7OScEE3MysJF3Qzs5JwQTcz\nKwkXdDOzknBBNzMrCRd0M7OScEE3MysJF3Qzs5JwQTczKwkXdDOzkmjk63N3k/QLSfelQaI/k+bP\nlrRM0rr0c9gRi8zMrDMaOUPfARwXEYeSjU60WNJRwEXAiohYCKxIbbNC6u3rq5gkKideGTL19Eyq\nmMyKru5faWSeS82+NAVwMnB9mn89cEpbEpqZWUMaOu2Q1JMGt9gCLIuIu4G5ETGQVtkEzK1xXw8S\nbWbWAQ0V9IjYFRGLgPnAEZLeWLU8yM7ah7uvB4k2M+uAUQ1wERFPS7oDWAxsljQvIgbS+KJb2pLQ\nJpxnnnmmon322WfXXaee6VMqz10+tnj/ivbM6UNPNq677rqK9k/WXj6qfQ5nyZIlFe0zzzyz6W2a\nDWrkXS57Sdoj3Z4KnAA8BNwGDP51LgFubVdIMzOrr5Ez9HnA9ZJ6yJ4AboqIpZJ+Btwk6RzgceDU\nNuY0M7M6Ghkkeg1w2DDztwHHtyOUmZmNngeJtsJ56aWXKtrLly8fss727dtHtc3JvZV/6kcc9oGK\n9u57vH7Ife5a++mK9u233z6qfQ7n6KOPbnobZrX40xJmZiXhgm5mVhIu6GZmJeGCbmZWEr4oaoXT\n19dX0Z4yZcqQdUZ9UXTKtIr2DmZXtKf17DHkPpN6h85r1uTJk1u+TbNBPkM3MysJF3Qzs5JwQTcz\nK4mO9qG/+OKLrFmzppO7tHHoqaeeqmjv3Lmz6W3u+H1ln/tNN364or1wv8ov6wLYNLC26f1WGxgY\nqGj7/8FayWfoZmYl4YJuZlYSzQwSfamkjZJWp+mk9sc1M7NaGulDHxwk+jlJfcBdkn6Yll0ZEZc1\nvLPeXjxqkdXT09NT0Z40qfkXki/vqhxQ65HfPDxiu12mT59e0fb/g7VSI1+fG8Bwg0SbmVmBNDNI\nNMBHJK2RdK2kWTXu+4dBordt29ai2GZmVq2ZQaKvAvYHFgEDwLADLuYHiZ4zZ06LYpuZWbUxDxKd\n7zuXdDWwtN79+/r6mDdv3uhT2oSy2267VbRb0YdeFDNmzKho+//BWmnMg0RLyv8lvhdo/acwzMys\nYc0MEv11SYvILpCuB85tX0wzM6unmUGiz2hLIjMzGxN/H7oVTvV3t+zYsaNLSVrv5Zdf7nYEK7Hy\nXG0yM5vgXNDNzErCBd3MrCRc0M3MSsIXRa1wqgdSPvHEE4es88wzz3QqTksdeOCB3Y5gJeYzdDOz\nknBBNzMrCRd0M7OScB+6Fc7MmTMr2jfffHOXkpiNLz5DNzMrCRd0M7OScEE3MysJZUOGdmhn0pPA\n48CewNaO7XjsnLO1xkPO8ZARnLPVip5zv4ioO6J4Rwv6H3YqrYyIwzu+41FyztYaDznHQ0ZwzlYb\nLznrcZeLmVlJuKCbmZVEtwr6l7u039FyztYaDznHQ0ZwzlYbLzlH1JU+dDMzaz13uZiZlYQLuplZ\nSXS0oEtaLOlhSY9KuqiT+65H0rWStkham5s3W9IySevSz1ldzrhA0h2SHpB0v6TzC5pzN0m/kHRf\nyvmZIuYcJKlH0i8lLU3twuWUtF7SryStlrSywDn3kHSzpIckPSjprUXKKemgdAwHp2clXVCkjM3o\nWEGX1AP8G/Au4GDgdEkHd2r/DfgqsLhq3kXAiohYCKxI7W7aCVwYEQcDRwHnpWNYtJw7gOMi4lBg\nEbBY0lEUL+eg84EHc+2i5nxHRCzKvV+6iDn/FfhRRLwBOJTsuBYmZ0Q8nI7hIuAtwAvALUXK2JSI\n6MgEvBX4ca59MXBxp/bfYMZ+YG2u/TAwL92eBzzc7YxVeW8FTihyTmAacC9wZBFzAvPJ/oGPA5YW\n9fcOrAf2rJpXqJzATOA3pDdbFDVnLteJwP8UOeNop052uewLPJFrb0jzimxuRAyk25uAud0Mkyep\nHzgMuJsC5kzdGKuBLcCyiChkTuALwCeAV3LzipgzgOWSVkn6YJpXtJyvA54ErktdWF+RNJ3i5Rx0\nGnBjul3UjKPii6INiuypuxDv8ZS0O/Ad4IKIeDa/rCg5I2JXZC9r5wNHSHpj1fKu55T0l8CWiFhV\na50i5EyOScfzXWRdbW/PLyxIzl7gzcBVEXEY8DxVXRcFyYmkycB7gG9XLytKxrHoZEHfCCzIteen\neUW2WdI8gPRzS5fzIKmPrJh/IyK+m2YXLuegiHgauIPs+kTRcr4NeI+k9cC3gOMk3UDxchIRG9PP\nLWR9vkdQvJwbgA3p1RjAzWQFvmg5IXtivDciNqd2ETOOWicL+j3AQkmvS8+OpwG3dXD/Y3EbsCTd\nXkLWZ901kgRcAzwYEVfkFhUt516S9ki3p5L18z9EwXJGxMURMT8i+sn+Hm+PiPdTsJySpkuaMXib\nrO93LQXLGRGbgCckHZRmHQ88QMFyJqfzancLFDPj6HX4IsRJwCPAr4FPdfsCQlW2G4EB4GWyM41z\ngDlkF8zWAcuB2V3OeAzZS8E1wOo0nVTAnG8CfplyrgX+Ic0vVM6qzMfy6kXRQuUE9gfuS9P9g/87\nRcuZMi0CVqbf/feAWUXLCUwHtgEzc/MKlXGskz/6b2ZWEr4oamZWEi7oZmYl4YJuZlYSLuhmZiXh\ngm5mVhIu6GZmJeGCbmZWEv8PR3wYn9oRioUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119d32cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resize = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize(40, interpolation=Image.CUBIC),\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "screen_width = 600\n",
    "\n",
    "def get_cart_location():\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return int(env.state[0] * scale + screen_width / 2.0)\n",
    "\n",
    "def get_screen():\n",
    "    screen = env.render(mode='rgb_array').transpose(\n",
    "        (2, 0, 1))  # transpose into torch order (CHW)\n",
    "    # Strip off the top and bottom of the screen\n",
    "    screen = screen[:, 160:320]\n",
    "    view_width = 320\n",
    "    cart_location = get_cart_location()\n",
    "    if cart_location < view_width // 2:\n",
    "        slice_range = slice(view_width)\n",
    "    elif cart_location > (screen_width - view_width // 2):\n",
    "        slice_range = slice(-view_width, None)\n",
    "    else:\n",
    "        slice_range = slice(cart_location - view_width // 2,\n",
    "                            cart_location + view_width // 2)\n",
    "    # Strip off the edges, so that we have a square image centered on a cart\n",
    "    screen = screen[:, :, slice_range]\n",
    "    # Convert to float, rescare, convert to torch tensor\n",
    "    # (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n",
    "\n",
    "policy_net = DQN().to(device)\n",
    "target_net = DQN().to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(2)]], device=device, dtype=torch.long)\n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "def plot_durations():\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    \n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "    \n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, batch.next_state)), device=device, dtype=torch.uint8)\n",
    "    non_final_next_stats = torch.cat([s for s in batch.next_state if s is not None])\n",
    "    \n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "    \n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "    \n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_stats).max(1)[0].detach()\n",
    "    \n",
    "    expected_state_action_value = (next_state_values * GAMMA) + reward\n",
    "    \n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_value.unsqueeze(1))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of type torch.LongTensor but found type torch.FloatTensor for argument #3 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-52ad1f13cbc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0moptimize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-d242d746cf64>\u001b[0m in \u001b[0;36moptimize_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mreward_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mstate_action_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mnext_state_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of type torch.LongTensor but found type torch.FloatTensor for argument #3 'index'"
     ]
    }
   ],
   "source": [
    "num_episodes = 50\n",
    "for i_episode in range(num_episodes):\n",
    "    env.reset()\n",
    "    last_screen = get_screen()\n",
    "    current_screen = get_screen()\n",
    "    state = current_screen - last_screen\n",
    "    for t in count():\n",
    "        action = select_action(state)\n",
    "        _, reward, done, _ = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        \n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen()\n",
    "        if not done:\n",
    "            next_state = current_screen - last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "        \n",
    "        memory.push(state, action, next_state, reward)\n",
    "        \n",
    "        state = next_state\n",
    "        \n",
    "        optimize_model()\n",
    "        \n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "        \n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
